{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "TimbreTransfer Rus.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tg-bomze/TimbreTransfer/blob/master/TimbreTransfer_Rus.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zIr0Xga092uC",
        "colab_type": "text"
      },
      "source": [
        "<b><font color=\"black\" size=\"+4\">Перенос тембра</font></b>\n",
        "\n",
        "<b><font color=\"black\" size=\"+2\">Базируется на:</font></b>\n",
        "\n",
        "**GitHub репозиторий**: [DDSP](https://github.com/magenta/ddsp)\n",
        "\n",
        "Статья: [DDSP: Differentiable Digital Signal Processing](https://openreview.net/forum?id=B1x1ma4tDr)\n",
        "\n",
        "Авторы: **[Jesse Engel](https://github.com/jesseengel), Lamtharn (Hanoi) Hantrakul, Chenjie Gu, [Adam Roberts](https://github.com/adarob).**\n",
        "\n",
        "<b><font color=\"black\" size=\"+2\">Колаб собрал:</font></b>\n",
        "\n",
        "GitHub: [@tg-bomze](https://github.com/tg-bomze),\n",
        "Telegram: [@bomze](https://t.me/bomze),\n",
        "Twitter: [@tg_bomze](https://twitter.com/tg_bomze).\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "Далее тыкай на кнопки (куда указывает красная стрелка) в каждом блоке поочередно. После нажатия дождись окончания выполнения.\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "colab_type": "code",
        "id": "6wZde6CBya9k",
        "colab": {}
      },
      "source": [
        "#@title <b><font color=\"red\" size=\"+3\">←</font><font color=\"black\" size=\"+3\"> Устанавливаем все необходимые компоненты</font></b>\n",
        "\n",
        "%tensorflow_version 2.x\n",
        "\n",
        "print('Installing from pip package...')\n",
        "!pip install -qU ddsp\n",
        "\n",
        "from IPython.display import clear_output\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "# Ignore a bunch of deprecation warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import copy\n",
        "import os\n",
        "import time\n",
        "\n",
        "import crepe\n",
        "import ddsp\n",
        "import ddsp.training\n",
        "from ddsp.colab.colab_utils import (download, play, record, specplot, upload,\n",
        "                                    DEFAULT_SAMPLE_RATE)\n",
        "import gin\n",
        "from google.colab import files\n",
        "import librosa\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow.compat.v2 as tf\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "# Helper Functions\n",
        "sample_rate = DEFAULT_SAMPLE_RATE  # 16000\n",
        "clear_output()\n",
        "print('Готово!')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "colab_type": "code",
        "id": "Go36QW9AS_CD",
        "colab": {}
      },
      "source": [
        "#@title <b><font color=\"red\" size=\"+3\">←</font><font color=\"black\" size=\"+3\"> Запишите или загрузите (.wav или .mp3) аудио</font></b>\n",
        "\n",
        "#@markdown * Внимание! Аудио должно быть монотонным (*один голос или один инструмент*)\n",
        "#@markdown * Если вы выбрали \"**Record**\", то запись начнется сразу же, как появится надпись \"**Starting recording for X seconds...**\"\n",
        "\n",
        "record_or_upload = \"Record\"  #@param [\"Record\", \"Upload (.mp3 or .wav)\"]\n",
        "\n",
        "record_seconds =   10  #@param {type:\"number\", min:1, max:10, step:1}\n",
        "\n",
        "if record_or_upload == \"Record\":\n",
        "  audio = record(seconds=record_seconds)\n",
        "else:\n",
        "  # Load audio sample here (.mp3 or .wav3 file)\n",
        "  # Just use the first file.\n",
        "  filenames, audios = upload()\n",
        "  audio = audios[0]\n",
        "audio = audio[np.newaxis, :]\n",
        "clear_output()\n",
        "\n",
        "# Plot.\n",
        "specplot(audio)\n",
        "play(audio)\n",
        "\n",
        "# Setup the session.\n",
        "ddsp.spectral_ops.reset_crepe()\n",
        "\n",
        "# Compute features.\n",
        "start_time = time.time()\n",
        "audio_features = ddsp.training.eval_util.compute_audio_features(audio)\n",
        "audio_features['loudness_db'] = audio_features['loudness_db'].astype(np.float32)\n",
        "audio_features_mod = None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "colab_type": "code",
        "id": "wmSGDWM5yyjm",
        "colab": {}
      },
      "source": [
        "#@title <b><font color=\"red\" size=\"+3\">←</font><font color=\"black\" size=\"+3\"> Выберите инструмент</font></b>\n",
        "#@markdown * **Violin** (Скрипка)\n",
        "\n",
        "#@markdown * **Flute** (Флейта)\n",
        "\n",
        "#@markdown * **Trumpet** (Труба)\n",
        "\n",
        "#@markdown * **Tenor_Saxophone** (Тенор саксофон)\n",
        "\n",
        "#@markdown * или загрузите свою собственную модель\n",
        "\n",
        "#@markdown ---\n",
        "\n",
        "model = 'Violin' #@param ['Violin', 'Flute', 'Flute2', 'Trumpet', 'Tenor_Saxophone','Upload your own (checkpoint folder as .zip)']\n",
        "MODEL = model\n",
        "#@markdown ---\n",
        "GCS_CKPT_DIR = 'gs://ddsp/models/tf2'\n",
        "\n",
        "def find_model_dir(dir_name):\n",
        "  # Iterate through directories until model directory is found\n",
        "  for root, dirs, filenames in os.walk(dir_name):\n",
        "    for filename in filenames:\n",
        "      if filename.endswith(\".gin\") and not filename.startswith(\".\"):\n",
        "        model_dir = root\n",
        "        break\n",
        "  return model_dir \n",
        "\n",
        "\n",
        "if model in ('Violin', 'Flute', 'Flute2', 'Trumpet', 'Tenor_Saxophone'):\n",
        "  # Pretrained models.\n",
        "  PRETRAINED_DIR = '/content/pretrained'\n",
        "  # Copy over from gs:// for faster loading.\n",
        "  !rm -r $PRETRAINED_DIR &> /dev/null\n",
        "  !mkdir $PRETRAINED_DIR &> /dev/null\n",
        "  model_dir = os.path.join(GCS_CKPT_DIR, 'solo_%s_ckpt' % model.lower())\n",
        "  !gsutil cp $model_dir/* $PRETRAINED_DIR &> /dev/null\n",
        "  model_dir = PRETRAINED_DIR\n",
        "  gin_file = os.path.join(model_dir, 'operative_config-0.gin')\n",
        "\n",
        "else:\n",
        "  # User models.\n",
        "  UPLOAD_DIR = '/content/uploaded'\n",
        "  !mkdir $UPLOAD_DIR\n",
        "  uploaded_files = files.upload()\n",
        "\n",
        "  for fnames in uploaded_files.keys():\n",
        "    print(\"Unzipping... {}\".format(fnames))\n",
        "    !unzip -o \"/content/$fnames\" -d $UPLOAD_DIR &> /dev/null\n",
        "  model_dir = find_model_dir(UPLOAD_DIR)\n",
        "  gin_file = os.path.join(model_dir, 'operative_config-0.gin')\n",
        "\n",
        "# Parse gin config,\n",
        "with gin.unlock_config():\n",
        "  gin.parse_config_file(gin_file, skip_unknown=True)\n",
        "\n",
        "# Assumes only one checkpoint in the folder, 'ckpt-[iter]`.\n",
        "ckpt_files = [f for f in tf.io.gfile.listdir(model_dir) if 'ckpt' in f]\n",
        "ckpt_name = ckpt_files[0].split('.')[0]\n",
        "ckpt = os.path.join(model_dir, ckpt_name)\n",
        "\n",
        "# Ensure dimensions and sampling rates are equal\n",
        "time_steps_train = gin.query_parameter('DefaultPreprocessor.time_steps')\n",
        "n_samples_train = gin.query_parameter('Additive.n_samples')\n",
        "hop_size = int(n_samples_train / time_steps_train)\n",
        "\n",
        "time_steps = int(audio.shape[1] / hop_size)\n",
        "n_samples = time_steps * hop_size\n",
        "\n",
        "# print(\"===Trained model===\")\n",
        "# print(\"Time Steps\", time_steps_train)\n",
        "# print(\"Samples\", n_samples_train)\n",
        "# print(\"Hop Size\", hop_size)\n",
        "# print(\"\\n===Resynthesis===\")\n",
        "# print(\"Time Steps\", time_steps)\n",
        "# print(\"Samples\", n_samples)\n",
        "# print('')\n",
        "\n",
        "gin_params = [\n",
        "    'Additive.n_samples = {}'.format(n_samples),\n",
        "    'FilteredNoise.n_samples = {}'.format(n_samples),\n",
        "    'DefaultPreprocessor.time_steps = {}'.format(time_steps),\n",
        "]\n",
        "\n",
        "with gin.unlock_config():\n",
        "  gin.parse_config(gin_params)\n",
        "\n",
        "\n",
        "# Trim all input vectors to correct lengths \n",
        "for key in ['f0_hz', 'f0_confidence', 'loudness_db']:\n",
        "  audio_features[key] = audio_features[key][:time_steps]\n",
        "audio_features['audio'] = audio_features['audio'][:, :n_samples]\n",
        "\n",
        "\n",
        "# Set up the model just to predict audio given new conditioning\n",
        "model = ddsp.training.models.Autoencoder()\n",
        "model.restore(ckpt)\n",
        "\n",
        "# Build model by running a batch through it.\n",
        "start_time = time.time()\n",
        "_ = model(audio_features, training=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "colab_type": "code",
        "id": "uQFUlIJ_5r36",
        "colab": {}
      },
      "source": [
        "#@title <b><font color=\"red\" size=\"+3\">←</font><font color=\"black\" size=\"+3\"> Модификация и синтез аудио</font></b>\n",
        "\n",
        "#@markdown Автокорректировка средней громкости, частоты и высоты тона (данная опция не всегда дает хороший результат):\n",
        "\n",
        "auto_adjust = True #@param{type:\"boolean\"}\n",
        "\n",
        "\n",
        "#@markdown *Контроль октавы (звук более глухой или звонкий):*\n",
        "f0_octave_shift =  0 #@param {type:\"slider\", min:-2, max:2, step:1}\n",
        "#@markdown *Контроль доверительного интервала звучания:*\n",
        "f0_confidence_threshold =  0 #@param {type:\"slider\", min:0.0, max:1.0, step:0.05}\n",
        "#@markdown *Контроль уровня громкости:*\n",
        "loudness_db_shift = 0 #@param {type:\"slider\", min:-20, max:20, step:1}\n",
        "\n",
        "#@markdown Экспериментируя с бегунками вы можете добиваться более реалистичного звучания\n",
        "\n",
        "audio_features_mod = {k: v.copy() for k, v in audio_features.items()}\n",
        "\n",
        "\n",
        "## Helper functions.\n",
        "def shift_ld(audio_features, ld_shift=0.0):\n",
        "  \"\"\"Shift loudness by a number of ocatves.\"\"\"\n",
        "  audio_features['loudness_db'] += ld_shift\n",
        "  return audio_features\n",
        "\n",
        "\n",
        "def shift_f0(audio_features, f0_octave_shift=0.0):\n",
        "  \"\"\"Shift f0 by a number of ocatves.\"\"\"\n",
        "  audio_features['f0_hz'] *= 2.0 ** (f0_octave_shift)\n",
        "  audio_features['f0_hz'] = np.clip(audio_features['f0_hz'], \n",
        "                                    0.0, \n",
        "                                    librosa.midi_to_hz(110.0))\n",
        "  return audio_features\n",
        "\n",
        "\n",
        "def mask_by_confidence(audio_features, confidence_level=0.1):\n",
        "  \"\"\"For the violin model, the masking causes fast dips in loudness. \n",
        "  This quick transient is interpreted by the model as the \"plunk\" sound.\n",
        "  \"\"\"\n",
        "  mask_idx = audio_features['f0_confidence'] < confidence_level\n",
        "  audio_features['f0_hz'][mask_idx] = 0.0\n",
        "  # audio_features['loudness_db'][mask_idx] = -ddsp.spectral_ops.LD_RANGE\n",
        "  return audio_features\n",
        "\n",
        "\n",
        "def smooth_loudness(audio_features, filter_size=3):\n",
        "  \"\"\"Smooth loudness with a box filter.\"\"\"\n",
        "  smoothing_filter = np.ones([filter_size]) / float(filter_size)\n",
        "  audio_features['loudness_db'] = np.convolve(audio_features['loudness_db'], \n",
        "                                           smoothing_filter, \n",
        "                                           mode='same')\n",
        "  return audio_features\n",
        "\n",
        "if auto_adjust:\n",
        "  if MODEL in ['Violin', 'Flute', 'Flute2', 'Trumpet', 'Saxophone', 'Tenor_Saxophone']:\n",
        "    # Adjust the peak loudness.\n",
        "    l = audio_features['loudness_db']\n",
        "    model_ld_avg_max = {\n",
        "        'Violin': -34.0,\n",
        "        'Flute': -45.0,\n",
        "        'Flute2': -44.0,\n",
        "        'Trumpet': -52.3,\n",
        "        'Tenor_Saxophone': -31.2\n",
        "    }[MODEL]\n",
        "    ld_max = np.max(audio_features['loudness_db'])\n",
        "    ld_diff_max = model_ld_avg_max - ld_max\n",
        "    audio_features_mod = shift_ld(audio_features_mod, ld_diff_max)\n",
        "\n",
        "    # Further adjust the average loudness above a threshold.\n",
        "    l = audio_features_mod['loudness_db']\n",
        "    model_ld_mean = {\n",
        "        'Violin': -44.0,\n",
        "        'Flute': -51.0,\n",
        "        'Flute2': -53.0,\n",
        "        'Trumpet': -69.2,\n",
        "        'Tenor_Saxophone': -50.8\n",
        "    }[MODEL]\n",
        "    ld_thresh = -70.0\n",
        "    ld_mean = np.mean(l[l > ld_thresh])\n",
        "    ld_diff_mean = model_ld_mean - ld_mean\n",
        "    audio_features_mod = shift_ld(audio_features_mod, ld_diff_mean)\n",
        "\n",
        "    # Shift the pitch register.\n",
        "    model_p_mean = {\n",
        "        'Violin': 73.0,\n",
        "        'Flute': 81.0,\n",
        "        'Flute2': 74.0,\n",
        "        'Trumpet': 65.8,\n",
        "        'Tenor_Saxophone': 57.8\n",
        "    }[MODEL]\n",
        "    p = librosa.hz_to_midi(audio_features['f0_hz'])\n",
        "    p[p == -np.inf] = 0.0\n",
        "    p_mean = p[l > ld_thresh].mean()\n",
        "    p_diff = model_p_mean - p_mean\n",
        "    p_diff_octave = p_diff / 12.0\n",
        "    round_fn = np.floor if p_diff_octave > 1.5 else np.ceil\n",
        "    p_diff_octave = round_fn(p_diff_octave)\n",
        "    audio_features_mod = shift_f0(audio_features_mod, p_diff_octave)\n",
        "\n",
        "  else:\n",
        "    print('\\nUser uploaded model: disabling auto-adjust.')\n",
        "\n",
        "  \n",
        "audio_features_mod = shift_ld(audio_features_mod, loudness_db_shift)\n",
        "audio_features_mod = shift_f0(audio_features_mod, f0_octave_shift)\n",
        "audio_features_mod = mask_by_confidence(audio_features_mod, f0_confidence_threshold)\n",
        "\n",
        "# Resynthesize Audio.\n",
        "af = audio_features if audio_features_mod is None else audio_features_mod\n",
        "\n",
        "# Run a batch of predictions.\n",
        "start_time = time.time()\n",
        "audio_gen = model(af, training=False)\n",
        "\n",
        "print('----------------------------------------------------------------------------------------------------')\n",
        "print('- Для скачивания аудиозаписи нажмите правой кнопкой мыши на плеер и выберите \"Сохранить аудио как\" -')\n",
        "print('----------------------------------------------------------------------------------------------------')\n",
        "print('\\n')\n",
        "\n",
        "# Audio.\n",
        "print('Resynthesis')\n",
        "play(audio_gen)\n",
        "\n",
        "print('Original')\n",
        "play(audio)\n",
        "\n",
        "# Plot\n",
        "specplot(audio_gen)\n",
        "plt.title(\"Resynthesis\")\n",
        "\n",
        "specplot(audio)\n",
        "_ = plt.title(\"Original\")"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}